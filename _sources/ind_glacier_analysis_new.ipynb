{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual glacier surface velocity analysis\n",
    "\n",
    "This notebook will build upon the data access and inspection steps in the earlier notebooks and demonstrate basic data analysis and visualization of surface velocity data at the scale of an individual glacier using xarray. \n",
    "\n",
    "*Learning goals*: \n",
    "- using xarray label-based indexing and selection tools\n",
    "- computation and grouped computation\n",
    "- visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "import flox\n",
    "\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itslivetools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen('https://its-live-data.s3.amazonaws.com/datacubes/catalog_v02.json') as url_catalog:\n",
    "    itslive_catalog = json.loads(url_catalog.read().decode())\n",
    "itslive_catalog.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = itslivetools.find_granule_by_point(itslive_catalog, [84.56, 28.54])\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = itslivetools.read_in_s3(url[0])\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_timesorted = dc.sortby(dc['mid_date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in vector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_asia = gpd.read_file('https://github.com/scottyhq/rgi/raw/main/15_rgi60_SouthAsiaEast.gpkg')\n",
    "se_asia.head(3)\n",
    "se_asia_prj = se_asia.to_crs('EPSG:32645')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_asia_prj.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a single glacier and subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_glacier_vec = se_asia_prj.loc[se_asia_prj['RGIId'] == 'RGI60-15.04714']\n",
    "sample_glacier_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip ITS_LIVE data to extent of sample glacier\n",
    "\n",
    "First, need to write the crs attr of the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_timesorted = dc_timesorted.rio.write_crs(f\"epsg:{dc_timesorted.mapping.attrs['spatial_epsg']}\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_glacier_raster = dc_timesorted.rio.clip(sample_glacier_vec.geometry, sample_glacier_vec.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_glacier_raster = sample_glacier_raster.drop_vars(mapping)\n",
    "sample_glacier_raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a look at a velocity time series\n",
    "\n",
    "Now that we have the velocity data clipped to a single glacier, let's explore the clipped dataset. The below cell plots the mean velocity across the x and y dimensions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_glacier_raster.v.mean(dim=['x','y']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there is a large amount of variability in the mean velocity over time. Let's use xarray tools to resample the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_obj = sample_glacier_raster.resample(mid_date = '1M')\n",
    "resample_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.resample()` is another grouping operation and returns an object of type `xarray.core.resample.DatasetResample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_glacier_resample_1m = resample_obj.mean(dim='mid_date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below plot is the initial velocity time series in blue, and the velocity data resampled to 1 month intervals in orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_glacier_raster.v.mean(dim=['x','y']).plot(label = 'Mean glacier speed')\n",
    "sample_glacier_resample_1m.v.mean(dim=['x','y']).plot(label = '1 month resample')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting! Despite what looks to be a pretty noisy signal looking at the full time series, we can start to pick out a seasonal signal and sub-annual velocity variability looking at the velocity data resampled into 1-month bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We could also calculate velocity anomalies... \n",
    "\n",
    "To do this, we will use xarray `groupby()` and `map()` \n",
    "\n",
    "\n",
    "following example from xarray tutorial\n",
    "\n",
    "We first define a function that subtracts the long-term mean from a single observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_time_mean(x):\n",
    "    return x-x.mean(dim='mid_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then group the dataset by month and apply the function to calculate the anomaly on each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_glacier_anom = sample_glacier_raster.groupby('mid_date.month').map(remove_time_mean)\n",
    "sample_glacier_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the velocity anomaly alongside the velocity time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols = 2, figsize=(17,7))\n",
    "sample_glacier_anom.v.mean(dim=['x','y']).plot(ax=axs[1]);\n",
    "sample_glacier_raster.v.mean(dim=['x','y']).plot(ax=axs[0]);\n",
    "axs[1].axhline(y=0, c = 'red', alpha = 0.5)\n",
    "axs[0].set_title('Glacier mean magnitude of velocity (m/y) over time series')\n",
    "axs[1].set_title('Glacier mean velocity anomaly (m/y) over time series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot we were taking the mean over the x and y dimensions. Let's take the mean along the mid_date dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols =2 , figsize=(16,7))\n",
    "sample_glacier_raster.mean(dim='mid_date').v.plot(ax = axs[0]);\n",
    "sample_glacier_anom.mean(dim='mid_date').v.plot(ax=axs[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped analysis by season\n",
    "We have a dense time series of surface velocity data for a single glacier. We can use xarray's `groupby()` to examine velocity variability further. We will start with using `groupby()` to break the velocity time series into seasonal means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_gb = sample_glacier_raster.groupby(sample_glacier_raster.mid_date.dt.season).mean()\n",
    "#add attrs to gb object\n",
    "seasons_gb.attrs = sample_glacier_raster.attrs \n",
    "seasons_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking down the above cell, we defined how we wanted to group our data (`sample_glacier_raster.mid_date.dt.season`) and the reduction we wanted to apply to each group (`mean()`). After the apply step, xarray automatically combines the groups into a single object. We can see that the `seasons_gb` object is an `xarray.Dataset` with the same dimensions and coordinates as the `sample_glacier_raster` object but that the `seasons_gb` object has a `seasons` dimension as well.\n",
    "\n",
    " If you'd like to see another example of this with more detailed explanations, go [here](https://tutorial.xarray.dev/fundamentals/03.2_groupby_with_xarray.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize velocity data across the seasonal groups we just defined, we can use xarray's `faceting` functionality. Faceting is a great way to visualize your data in 'small multiples' format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = seasons_gb.v.plot(\n",
    "    col='season',\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols =3, figsize=(20,5))\n",
    "sample_glacier_raster.v.sel(x = 246052.5, y= 3181987.5).plot(ax=axs[0])\n",
    "sample_glacier_raster.v.mean(dim=['x','y']).plot(ax=axs[0], alpha = 0.5)\n",
    "sample_glacier_raster.v.mean(dim='mid_date').plot(ax=axs[1])\n",
    "axs[1].axvline(x=246052.5, c= 'red')\n",
    "axs[1].axhline(y=3181987.5, c='red')\n",
    "(sample_glacier_raster.v.sel(x = 246052.5, y= 3181987.5) - sample_glacier_raster.v.mean(dim=['x','y'])).plot(ax=axs[2], linewidth=0, marker='o', alpha = 0.5)\n",
    "axs[0].set_title('Time series of average glacier speed (orange) \\n and speed at point in accumulation zone (blue')\n",
    "axs[2].set_title('Point speed - mean glacier speed')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
