{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71327c0e",
   "metadata": {},
   "source": [
    "# Software and Data\n",
    "\n",
    "On this page you'll find information about the computing environment and datasets that we'll be using in this tutorial.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da78ab9",
   "metadata": {},
   "source": [
    "##  A. Software Packages\n",
    "\n",
    "Below, you'lll see a list of the python libraries we'll be using in this chapter (note:wording updated for when books are combined). This is the full list of libraries across all notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446021e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rioxarray as rio\n",
    "import s3fs\n",
    "import scipy.stats\n",
    "from shapely.geometry import Point, Polygon\n",
    "from typing import Union\n",
    "import warnings\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43c7d3b",
   "metadata": {},
   "source": [
    "This tutorial also uses several functions that are stored in the script [`itslivetools.py`](https://github.com/e-marshall/itslive/blob/master/itslivetools.py). It is located in the github repo for this tutorial. If you clone the repo, it should be available to import to the tutorial notebooks. Otherwise, if you would like to use `itslivetools.py`, download the script and move it to your working directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c34458",
   "metadata": {},
   "source": [
    "## B. Computational Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35049ecb",
   "metadata": {},
   "source": [
    "### Running tutorial on the cloud\n",
    "\n",
    "This link will launch a preconfigured jupyterlab environment on mybinder.org:\n",
    "\n",
    "[https://mybinder.org/v2/gh/e-marshall/itslive/HEAD?labpath=accessing_s3_data.ipynb](https://mybinder.org/v2/gh/e-marshall/itslive/HEAD?labpath=accessing_s3_data.ipynb)\n",
    "\n",
    "### Running tutorial material locally\n",
    "\n",
    "To run the notebooks contained in this tutorial on your local machine\n",
    "\n",
    "create the `itslivetools_env` conda environment (`conda env create -f environment-unpinned.yml`) based on the `environment.yml` file [here](https://github.com/e-marshall/mynewbook/blob/master/environment.yml). This should work on any platform (linux, osx, windows) and will install the latest versions of all dependencies.\n",
    "\n",
    "Alternatively, the code repository for this tutorial (https://github.com/e-marshall/itslive) also contains \"lock\" files for Linux (conda-linux-64.lock.yml) and MacOS (conda-osx-64.lock.yml) that pin exact versions of all required python packages for a [reproducible computing environment](https://mybinder.readthedocs.io/en/latest/tutorials/reproducibility.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b773e4",
   "metadata": {},
   "source": [
    "## C. Data used in this chapter\n",
    "\n",
    "### ITS_LIVE\n",
    "\n",
    "The velocity data that we'll be using is from the  [ITS_LIVE dataset](https://its-live.jpl.nasa.gov/#access). This dataset contains global coverage of land ice velocity data at various temporal frequencies and in various formats. Follow the link to explore the data that's available for a particular region you may be interested in. **ITS_LIVE** has multiple options for data access; this example will focus on using zarr datacubes that are stored in s3 buckets on AWS.\n",
    "\n",
    "**ITS_LIVE** velocity data is accessed in a raster format and the data covers a large swath of terrain covering land that is glaciated and non-glaciated. We want to select just the pixels that cover glaciated surfaces; to do this, we use glacier outlines from the [Randolph Glacier Inventory](https://www.glims.org/RGI/). The RGI region used in this tutorial is made available as a [GeoParquet](https://geoparquet.org/) file in the tutorial [repository](https://github.com/e-marshall/itslive/blob/master/rgi7_region15_south_asia_east.parquet). \n",
    "\n",
    "Head to the next page to see how we start accessing and working with this data.\n",
    "\n",
    "### RGI\n",
    "\n",
    "The Randolph Glacier Inventory is a global, publicly available dataset of containing glacier outlines, centerlines and attribute information that has been compiled over decades from many studies. It is a very valuable resource for glaciology research. Read more about the RGI project and the most recent version, V7, [here](http://www.glims.org/rgi_user_guide/welcome.html)\n",
    "\n",
    "rewrite but incorporate these points (from initial_velocity_data_inspection):\n",
    "We will read in just one region of the RGI (region 15, SouthAsiaEast). RGI data is downloaded in lat/lon coordinates. We will project it to match the coordinate reference system (CRS) of the ITS_LIVE dataset and then select an individual glacier to begin our analysis. ITS_LIVE data is in the Universal Transverse Mercator (UTM) coordinate system, and each datacube is projected to the UTM zone specific to its location. You can read more about these concepts [here](https://sites.math.washington.edu/~king/coursedir/m445w05/as/projects/Universal%20Transverse%20Mercator%20Geometry3.pdf).\n",
    "\n",
    "RGI data is publicly available here, however, for ease-of-use we have saved a single region of the dataset in this repository as a GeoParquet file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itslive_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
